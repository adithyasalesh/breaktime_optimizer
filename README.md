# ğŸ“š Study Break Optimizer - RL Edition

A professional web application that uses **Reinforcement Learning (Q-Learning)** to provide intelligent study break recommendations. The system learns optimal break timing based on study duration and fatigue levels.

## ğŸ¯ Features

- **AI-Powered Recommendations**: Q-Learning agent suggests optimal break times
- **Interactive Dashboard**: Real-time monitoring of study sessions
- **Agent Training**: Train the RL agent with custom episode counts
- **Performance Analytics**: Track training progress with reward charts
- **Responsive Design**: Works on desktop and mobile devices
- **RESTful API**: Clean API for all operations

## ğŸ› ï¸ Tech Stack

- **Backend**: Flask (Python)
- **Frontend**: HTML5, CSS3, JavaScript
- **ML Framework**: NumPy
- **Visualization**: Chart.js

## ğŸ“‹ Prerequisites

- Python 3.8+
- pip (Python package manager)

## ğŸš€ Installation & Setup

### 1. Clone/Download the project
```bash
cd StudyBreakOptimizer_RL
```

### 2. Create a virtual environment (optional but recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the application
```bash
python app.py
```

### 5. Open in browser
Navigate to: **http://localhost:5000**

## ğŸ“– How to Use

### Session Management
1. **View Status**: Monitor current study time and fatigue level
2. **Get Recommendations**: AI suggests your next action (Continue/Short Break/Long Break)
3. **Take Actions**: Follow recommendations to get reward feedback
4. **Reset Session**: Start a fresh study session anytime

### Training the Agent
1. Set the number of episodes (default: 100)
2. Click "Start Training"
3. Watch the progress bar and performance metrics update
4. View reward trends in the chart

### Actions Available
- **Continue Studying** (ğŸ“š): Keep studying for 10 more minutes
- **Short Break** (â˜•): Take a 5-minute break to reduce fatigue
- **Long Break** (ğŸ›ï¸): Take a 15-minute break for deeper recovery

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/status` | Get current session status |
| POST | `/api/action` | Execute an action |
| GET | `/api/recommendation` | Get AI recommendation |
| POST | `/api/train` | Train agent for N episodes |
| GET | `/api/training-status` | Get training progress |
| GET | `/api/stats` | Get training statistics |
| POST | `/api/reset` | Reset session |

### Example: Take an Action
```bash
curl -X POST http://localhost:5000/api/action \
  -H "Content-Type: application/json" \
  -d '{"action": 1}'
```

## ğŸ¤– Reinforcement Learning Details

### Algorithm
- **Type**: Q-Learning
- **States**: 9 possible states (3 time levels Ã— 3 fatigue levels)
- **Actions**: 3 actions (Continue/Short Break/Long Break)
- **Hyperparameters**:
  - Learning Rate (Î±): 0.1
  - Discount Factor (Î³): 0.9
  - Exploration Rate (Îµ): 0.2

### Training
- Episodes: Configurable (default 100)
- Each episode runs until study_time â‰¥ 120 minutes
- Rewards: Actions give immediate feedback (-1 for studying, +2/+4 for breaks)

## ğŸ“ Project Structure

```
StudyBreakOptimizer_RL/
â”œâ”€â”€ app.py                    # Flask application
â”œâ”€â”€ environment.py            # Study environment
â”œâ”€â”€ q_learning_agent.py      # Q-Learning agent
â”œâ”€â”€ train.py                 # Training script (legacy)
â”œâ”€â”€ ui.py                    # Tkinter UI (legacy)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Main web interface
â””â”€â”€ static/
    â”œâ”€â”€ style.css           # Styling
    â””â”€â”€ script.js           # Frontend logic
```

## ğŸ”§ Configuration

Modify hyperparameters in `q_learning_agent.py`:
```python
self.alpha = 0.1      # Learning rate
self.gamma = 0.9      # Discount factor
self.epsilon = 0.2    # Exploration rate
```

Adjust environment parameters in `environment.py`:
```python
# Time thresholds
if self.study_time < 30:  # Change 30 to adjust
    time_state = 0
```

## ğŸ“ˆ Performance Tips

1. **Train more episodes** for better performance
2. **Monitor the rewards chart** to see learning progress
3. **Adjust hyperparameters** if convergence is slow
4. **Reset sessions** frequently to collect diverse training data

## ğŸ› Troubleshooting

### Port already in use
Change the port in `app.py`:
```python
if __name__ == '__main__':
    app.run(debug=True, port=5001)  # Change 5000 to 5001
```

### Module not found errors
Ensure all dependencies are installed:
```bash
pip install -r requirements.txt
```

## ğŸš€ Deployment

### Production Deployment (Gunicorn)
```bash
pip install gunicorn
gunicorn app:app --bind 0.0.0.0:5000
```

### Docker (Optional)
Create a `Dockerfile`:
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["gunicorn", "app:app", "--bind", "0.0.0.0:5000"]
```

## ğŸ“ License

This project is proprietary and strictly belongs to the author. All rights reserved. No use, reproduction, modification, or distribution is permitted without explicit written permission.

## ğŸ‘¨â€ğŸ’» Author

Created as a Reinforcement Learning demonstration project.

## ğŸ¤ Contributing

Feel free to fork, modify, and improve this project!

---

**Happy studying with AI! ğŸš€**
